LOAD CSV WITH HEADERS FROM "file:///nodes_to_graph_id.csv" AS csvLine1
MERGE (u:User
 { 
    node_id: coalesce(csvLine1.user_node_id, "No user_node_id"),
    graph_id: coalesce(csvLine1.graph_id, "No graph_id"),
    label: coalesce(csvLine1.label, "No label")
 }
);


LOAD CSV WITH HEADERS FROM "file:///edges.csv" AS csvLine2
MATCH (u1:User { node_id: csvLine2.from })
MATCH (u2:User { node_id: csvLine2.to })
MERGE (u1)-[:retweeted_post_of]->(u2)

// verify datasets, mean should be like in GNN-fake-news-detection on github

// create graph projection
CALL gds.graph.project('retweet_network','User','retweeted_post_of');

CALL gds.wcc.stats('retweet_network')
YIELD componentCount, componentDistribution
RETURN componentCount, 
       componentDistribution.min as min,
       componentDistribution.max as max,
       componentDistribution.mean as mean


// How many users with more than 1 relation

MATCH (u:User)
WHERE size((u)-[:retweeted_post_of]-()) > 1
RETURN u

// compute betweenness for true labeled nodes

// CALL gds.betweenness.stream('retweet_network')
// YIELD nodeId, score
// MATCH (user: User { label: "1.0"} ) WHERE id(user) = nodeId
// RETURN user.node_id, score
// ORDER BY score DESC

// export betweenness correlation data

CALL apoc.export.csv.query("
CALL gds.betweenness.stream('retweet_network')
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as betweenness_score
ORDER BY nodeId ASC", 'betweenness_to_label.csv', {});

// export closeness correlation data Wasserman and Faust

CALL apoc.export.csv.query("
CALL gds.beta.closeness.stream('retweet_network', {useWassermanFaust: true})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as closeness_score
ORDER BY nodeId ASC", 'closeness_to_label.csv', {});


// export harmonic closeness

CALL apoc.export.csv.query("
CALL gds.alpha.closeness.harmonic.stream('retweet_network')
YIELD nodeId, centrality
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, centrality as harmonic_closeness_centrality
ORDER BY nodeId ASC", 'harmonic_closeness_to_label.csv', {});

// export degree correlation data

CALL apoc.export.csv.query("MATCH (user:User)
WITH user, id(user) as nodeId, size([(user)-[:retweeted_post_of]->() | user]) as outDegree, size([(user)<-[:retweeted_post_of]-() | user]) as inDegree
WHERE id(user) = nodeId
RETURN user.label, outDegree, inDegree, inDegree + outDegree as degree
ORDER BY nodeId ASC", 'degree_to_label.csv', {});

// PageRank

CALL apoc.export.csv.query("CALL gds.pageRank.stream('retweet_network', {maxIterations: 20, dampingFactor: 0.85})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as page_rank_score
ORDER BY nodeId ASC", 'page_rank_to_label.csv', {});

// ArticleRank
CALL apoc.export.csv.query("CALL gds.articleRank.stream('retweet_network', {maxIterations: 20, dampingFactor: 0.85})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as page_rank_score
ORDER BY nodeId ASC", 'article_rank_to_label.csv', {});


// Eigenvector
CALL apoc.export.csv.query("CALL gds.eigenvector.stream('retweet_network', {maxIterations: 40})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as eigenvector_score
ORDER BY nodeId ASC", 'eigenvector_to_label.csv', {});

// HITS
CALL apoc.export.csv.query("CALL gds.alpha.hits.stream('retweet_network', {hitsIterations: 50})
YIELD nodeId, values
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, values.hub as hits_hub, values.auth as hits_auth
ORDER BY nodeId ASC", 'hits_to_label.csv', {});


LOAD CSV WITH HEADERS FROM "file:///tweets_processed.csv" AS csvLine
MERGE (u:User
 { 
    twitter_id: coalesce(csvLine.user_id, "unknown")
 }
)
MERGE (t: Tweet
 { 
    twitter_id: coalesce(csvLine.id, "unknown"),
    text: coalesce(csvLine.id, "unknown"),
    source: coalesce(csvLine.source, "unknown"),
    createdAt: coalesce(apoc.date.parse(csvLine.timestamp, "ms", "yyyy-MM-dd HH:mm:ss"), "unknown"),
    possibly_sensitive: coalesce(csvLine.possibly_sensitive, "unknown"),
    place: coalesce(csvLine.place, "unknown")
 }
)
MERGE (t)-[:postedBy]->(u)



LOAD CSV WITH HEADERS FROM "file:///tweets_processed.csv" AS csvLine
MERGE (u:User
 { 
    twitter_id: coalesce(csvLine.user_id, "unknown")
 }
)
MERGE (t: Tweet
 { 
    twitter_id: coalesce(csvLine.id, "unknown"),
    text: coalesce(csvLine.id, "unknown"),
    source: coalesce(csvLine.source, "unknown"),
    createdAt: coalesce(apoc.date.parse(csvLine.timestamp, "ms", "yyyy-MM-dd HH:mm:ss"), "unknown"),
    possibly_sensitive: coalesce(csvLine.possibly_sensitive, "unknown"),
    place: coalesce(csvLine.place, "unknown")
 }
)
MERGE (t)-[:postedBy]->(u)


dbms.memory.heap.initial_size=1G
dbms.memory.heap.max_size=10G
dbms.memory.pagecache.size=1G


CREATE CONSTRAINT FOR (u:User) REQUIRE u.twitterId IS UNIQUE;
CREATE CONSTRAINT FOR (t:Tweet) REQUIRE t.twitterId IS UNIQUE;


:auto LOAD CSV WITH HEADERS FROM "file:///tweets_processed.csv" AS csvLine
CALL {
    
WITH csvLine
MERGE (u:User { twitterId: csvLine.user_id })
CREATE (t: Tweet
 {  twitterId: csvLine.id,
    text: coalesce(csvLine.text, "unknown"),
    source: coalesce(csvLine.source, "unknown"),
    createdAt: coalesce(date(datetime({ epochmillis: 
apoc.date.parse(csvLine.timestamp, "ms", "yyyy-MM-dd HH:mm:ss") })), "unknown"),
    possibly_sensitive: coalesce(csvLine.possibly_sensitive, "unknown"),
    place: coalesce(csvLine.place, "unknown")
 }
)
CREATE (t)-[:postedBy]->(u)
} IN TRANSACTIONS OF 50000 ROWS


// MATCH (t: Tweet) DETACH DELETE t;
// MATCH (u: User) DETACH DELETE u;

LOAD CSV WITH HEADERS FROM "file:///tweets_processed.csv" AS csvLine
WITH csvLine.in_reply_to_status_id as in_reply_to_status_id 
WHERE in_reply_to_status_id <> '0'
MERGE (t2: Tweet { twitterId: in_reply_to_status_id});

LOAD CSV WITH HEADERS FROM "file:///tweets_processed.csv" AS csvLine
WITH csvLine.retweeted_status_id as retweeted_status_id
WHERE retweeted_status_id <> '0'
MERGE (t3: Tweet { twitterId: retweeted_status_id});

:auto LOAD CSV WITH HEADERS FROM "file:///tweets_processed.csv" AS csvLine
CALL {
WITH csvLine
MATCH (t1: Tweet { twitterId: csvLine.id })
MATCH (t2: Tweet { twitterId: csvLine.in_reply_to_status_id})
MERGE (t1)-[:inReplyToStatus { screenName: coalesce(csvLine.in_reply_to_screen_name, 'unknown') }]->(t2)
} IN TRANSACTIONS OF 50000 ROWS


:auto LOAD CSV WITH HEADERS FROM "file:///tweets_processed.csv" AS csvLine
CALL {
WITH csvLine
MATCH (t1: Tweet { twitterId: csvLine.id })
MATCH (t2: Tweet { twitterId: csvLine.retweeted_status_id})
MERGE (t1)-[:retweetedStatus]->(t2)
} IN TRANSACTIONS OF 50000 ROWS


MATCH (u1: User)<-[:postedBy]-(t1: Tweet)-[:inReplyToStatus]->(t2: Tweet)-[:postedBy]->(u2: User)
MERGE (u1)-[i:interacted {inReplyToStatus: true}]->(u2)
RETURN u1, u2, i

MATCH (u1: User)<-[:postedBy]-(t1: Tweet)-[:retweetedStatus]->(t2: Tweet)-[:postedBy]->(u2: User)
MERGE (u1)-[i:interacted]->(u2)
ON MATCH
  SET
    i.retweetedStatus = true


CALL gds.graph.project('interaction_network','User','interacted');


CALL apoc.export.csv.query("
CALL gds.betweenness.stream('interaction_network')
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as betweenness_score
ORDER BY nodeId ASC", 'betweenness_to_label.csv', {});

// export closeness correlation data Wasserman and Faust

CALL apoc.export.csv.query("
CALL gds.beta.closeness.stream('interaction_network', {useWassermanFaust: true})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as closeness_score
ORDER BY nodeId ASC", 'closeness_to_label.csv', {});


// export harmonic closeness

CALL apoc.export.csv.query("
CALL gds.alpha.closeness.harmonic.stream('interaction_network')
YIELD nodeId, centrality
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, centrality as harmonic_closeness_centrality
ORDER BY nodeId ASC", 'harmonic_closeness_to_label.csv', {});

// export degree correlation data

CALL apoc.export.csv.query("MATCH (user:User)
WITH user, id(user) as nodeId, size([(user)-[:retweeted_post_of]->() | user]) as outDegree, size([(user)<-[:retweeted_post_of]-() | user]) as inDegree
WHERE id(user) = nodeId
RETURN user.label, outDegree, inDegree, inDegree + outDegree as degree
ORDER BY nodeId ASC", 'degree_to_label.csv', {});

// PageRank

CALL apoc.export.csv.query("CALL gds.pageRank.stream('interaction_network', {maxIterations: 20, dampingFactor: 0.85})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as page_rank_score
ORDER BY nodeId ASC", 'page_rank_to_label.csv', {});

// ArticleRank
CALL apoc.export.csv.query("CALL gds.articleRank.stream('interaction_network', {maxIterations: 20, dampingFactor: 0.85})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as page_rank_score
ORDER BY nodeId ASC", 'article_rank_to_label.csv', {});


// Eigenvector
CALL apoc.export.csv.query("CALL gds.eigenvector.stream('interaction_network', {maxIterations: 40})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as eigenvector_score
ORDER BY nodeId ASC", 'eigenvector_to_label.csv', {});

// HITS
CALL apoc.export.csv.query("CALL gds.alpha.hits.stream('interaction_network', {hitsIterations: 50})
YIELD nodeId, values
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, values.hub as hits_hub, values.auth as hits_auth
ORDER BY nodeId ASC", 'hits_to_label.csv', {});


CALL gds.graph.project.cypher(
  'tweets_interactions_network',
  'MATCH (t1: Tweet) WHERE t1:Tweet RETURN id(t1) AS id',
  'MATCH (t1)-[r:retweetedStatus|inReplyToStatus]->(t2) RETURN id(t1) AS source, id(t2) AS target')



CALL apoc.export.csv.query("
CALL gds.betweenness.stream('interaction_network')
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as betweenness_score
ORDER BY nodeId ASC", 'betweenness_to_label.csv', {});

// export closeness correlation data Wasserman and Faust

CALL apoc.export.csv.query("
CALL gds.beta.closeness.stream('interaction_network', {useWassermanFaust: true})
YIELD nodeId, score
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, score as closeness_score
ORDER BY nodeId ASC", 'closeness_to_label.csv', {});


// export harmonic closeness

CALL apoc.export.csv.query("
CALL gds.alpha.closeness.harmonic.stream('interaction_network')
YIELD nodeId, centrality
MATCH (user: User) WHERE id(user) = nodeId
RETURN user.label, centrality as harmonic_closeness_centrality
ORDER BY nodeId ASC", 'harmonic_closeness_to_label.csv', {});

// export degree correlation data

CALL apoc.export.csv.query("MATCH (user:User)
WITH user, id(user) as nodeId, size([(user)-[:retweeted_post_of]->() | user]) as outDegree, size([(user)<-[:retweeted_post_of]-() | user]) as inDegree
WHERE id(user) = nodeId
RETURN user.label, outDegree, inDegree, inDegree + outDegree as degree
ORDER BY nodeId ASC", 'degree_to_label.csv', {});


:sysinfo

## with gossipcop
:auto LOAD CSV WITH HEADERS FROM "file:///nodes_to_graph_id.csv" AS csvLine1
CALL {
WITH csvLine1
MERGE (u:User
 { 
    node_id: coalesce(csvLine1.user_node_id, "No user_node_id")
 })
ON CREATE SET u.graph_id = coalesce(csvLine1.graph_id, "No graph_id"), u.label = coalesce(csvLine1.label, "No label")
} IN TRANSACTIONS OF 10000 ROWS;

:auto LOAD CSV WITH HEADERS FROM "file:///edges.csv" AS csvLine2
CALL {
WITH csvLine2
MATCH (u1:User { node_id: csvLine2.from })
MATCH (u2:User { node_id: csvLine2.to })
MERGE (u1)-[:retweeted_post_of]->(u2)
} IN TRANSACTIONS OF 10000 ROWS;